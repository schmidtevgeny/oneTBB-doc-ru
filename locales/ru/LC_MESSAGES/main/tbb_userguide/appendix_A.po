# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2021, Intel Corporation
# This file is distributed under the same license as the oneTBB package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2022.
#
msgid ""
msgstr ""
"Project-Id-Version: oneTBB\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2022-02-23 14:08+0300\n"
"PO-Revision-Date: 2022-05-02 20:34+0300\n"
"Last-Translator: Evgeny <schmidte@list.ru>\n"
"Language-Team: \n"
"Language: ru_RU\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Plural-Forms: nplurals=3; plural=(n%10==1 && n%100!=11 ? 0 : n%10>=2 && n%10<=4 && (n%100<12 || n%100>14) ? 1 : 2);\n"
"Generated-By: Babel 2.9.1\n"
"X-Generator: Poedit 3.0.1\n"

#: ../../oneTBB/doc/main/tbb_userguide/appendix_A.rst:4
msgid "Appendix A Costs of Time Slicing"
msgstr "Приложение A Затраты на распределение времени"

#: ../../oneTBB/doc/main/tbb_userguide/appendix_A.rst:7
msgid "Time slicing enables there to be more logical threads than physical threads. Each logical thread is serviced for a *time slice* by a physical thread. If a thread runs longer than a time slice, as most do, it relinquishes the physical thread until it gets another turn. This appendix details the costs incurred by time slicing."
msgstr "Временной срез позволяет иметь больше логических потоков, чем физических. Каждый логический поток обслуживается в течение *временного среза* физическим потоком. Если поток работает дольше временного среза, а так происходит в большинстве случаев, он отказывается от физического потока до тех пор, пока не получит новую очередь. В этом приложении подробно описаны затраты, связанные с временным срезом."

#: ../../oneTBB/doc/main/tbb_userguide/appendix_A.rst:14
msgid "The most obvious is the time for *context switching* between logical threads. Each context switch requires that the processor save all its registers for the previous logical thread that it was executing, and load its registers for the next logical thread that it runs."
msgstr "Наиболее очевидным является время на *переключение контекста* между логическими потоками. Каждое переключение контекста требует, чтобы процессор сохранил все свои регистры для предыдущего логического потока, который он выполнял, и загрузил свои регистры для следующего логического потока, который он запускает."

#: ../../oneTBB/doc/main/tbb_userguide/appendix_A.rst:20
msgid "A more subtle cost is *cache cooling*. Processors keep recently accessed data in cache memory, which is very fast, but also relatively small compared to main memory. When the processor runs out of cache memory, it has to evict items from cache and put them back into main memory. Typically, it chooses the least recently used items in the cache. (The reality of set-associative caches is a bit more complicated, but this is not a cache primer.) When a logical thread gets its time slice, as it references a piece of data for the first time, this data will be pulled into cache, taking hundreds of cycles. If it is referenced frequently enough to not be evicted, each subsequent reference will find it in cache, and only take a few cycles. Such data is called \"hot in cache\". Time slicing undoes this, because if a thread A finishes its time slice, and subsequently thread B runs on the same physical thread, B will tend to evict data that was hot in cache for A, unless both threads need the data. When thread A gets its next time slice, it will need to reload evicted data, at the cost of hundreds of cycles for each cache miss. Or worse yet, the next time slice for thread A may be on a different physical thread that has a different cache altogether."
msgstr "Более тонкая стоимость - это *охлаждение кэш-памяти*. Процессоры хранят данные, к которым недавно обращались, в кэш-памяти, которая очень быстра, но также относительно мала по сравнению с основной памятью. Когда процессор исчерпывает кэш-память, ему приходится изгонять элементы из кэша и помещать их обратно в основную память. Как правило, он выбирает наименее недавно использованные элементы в кэше. (Реальность кэш-памяти с множеством ассоциаций немного сложнее, но это не учебник по кэш-памяти) Когда логический поток получает свой временной срез, когда он впервые обращается к части данных, эти данные будут втянуты в кэш, что займет сотни циклов. Если на него ссылаются достаточно часто, чтобы не быть выселенными, то каждое последующее обращение будет находить его в кэше и займет всего несколько циклов. Такие данные называются \"горячими в кэше\". Временной срез отменяет это, потому что если поток A завершает свой временной срез, а затем поток B работает на том же физическом потоке, B будет склонен вытеснять данные, которые были \"горячими\" в кэше для A, если только оба потока не нуждаются в этих данных. Когда поток А получит свой следующий временной срез, ему придется заново загружать вытесненные данные, затрачивая сотни тактов на каждый промах в кэше. Или, что еще хуже, следующий временной срез для потока A может быть на другом физическом потоке, который имеет совсем другой кэш."

#: ../../oneTBB/doc/main/tbb_userguide/appendix_A.rst:40
msgid "Another cost is *lock preemption.* This happens if a thread acquires a lock on a resource, and its time slice runs out before it releases the lock. No matter how short a time the thread intended to hold the lock, it is now going to hold it for at least as long as it takes for its next turn at a time slice to come up. Any other threads waiting on the lock either pointlessly busy-wait, or lose the rest of their time slice. The effect is called *convoying*, because the threads end up \"bumper to bumper\" waiting for the preempted thread in front to resume driving."
msgstr "Другая издержка - *предоставление блокировки.* Это происходит, если поток приобретает блокировку на ресурсе, и его временной срез заканчивается до того, как он освободит блокировку. Независимо от того, насколько короткое время поток намеревался удерживать блокировку, теперь он будет удерживать её как минимум столько, сколько потребуется для того, чтобы подошла его следующая очередь на временной срез. Любые другие потоки, ожидающие блокировку, либо бессмысленно заняты ожиданием, либо теряют остаток своего временного среза. Этот эффект называется *конвоированием*, потому что потоки оказываются \"бампер к бамперу\", ожидая, когда вытесненный поток впереди возобновит движение."
